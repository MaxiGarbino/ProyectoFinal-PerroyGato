{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#In[1]\n",
    "\"\"\"\n",
    "En cada compu antes de ejecutar hay que ejecutar los siguientes comandos:\n",
    "\n",
    "pip install -r requirements.txt\n",
    "\"\"\" \n",
    "\n",
    "import os\n",
    "import shutil\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import plotly.express as px\n",
    "import scipy as sp\n",
    "\n",
    "from scipy import ndimage\n",
    "from shutil import copyfile\n",
    "from tensorflow.keras.layers import Conv2D,Add,MaxPooling2D, Dense, BatchNormalization,Input\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import LearningRateScheduler\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#In[2]\n",
    "\n",
    "class_names = ['Cat', 'Dog']\n",
    "\n",
    "module_dir = os.path.dirname(__file__)\n",
    "print(module_dir)\n",
    "\n",
    "dogs_folder = os.path.join(module_dir, 'kaggle', 'input', 'microsoft-catsvsdogs-dataset', 'PetImages', 'Dog')\n",
    "cats_folder = os.path.join(module_dir, 'kaggle', 'input', 'microsoft-catsvsdogs-dataset', 'PetImages', 'Cat')\n",
    "\n",
    "n_dogs = len(os.listdir(dogs_folder))\n",
    "n_cats = len(os.listdir(cats_folder))\n",
    "n_images = [n_cats, n_dogs]\n",
    "px.pie(names=class_names, values=n_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#In[3]\n",
    "\n",
    "try:\n",
    "    \n",
    "    os.mkdir(os.path.join(module_dir, \"tmp\"))\n",
    "    os.mkdir(os.path.join(module_dir, \"tmp\", \"cats-v-dogs\"))\n",
    "    os.mkdir(os.path.join(module_dir,\"tmp\",\"training\"))\n",
    "    os.mkdir(os.path.join(module_dir,\"tmp\",\"validation\"))\n",
    "    os.mkdir(os.path.join(module_dir,\"tmp\",\"test\"))\n",
    "    os.mkdir(os.path.join(module_dir,\"tmp\",\"training/cats\"))\n",
    "    os.mkdir(os.path.join(module_dir,\"tmp\",\"training/dogs\"))\n",
    "    os.mkdir(os.path.join(module_dir,\"tmp\",\"validation/cats\"))\n",
    "    os.mkdir(os.path.join(module_dir,\"tmp\",\"validation/dogs\"))\n",
    "    os.mkdir(os.path.join(module_dir,\"tmp\",\"test/cats\"))\n",
    "    os.mkdir(os.path.join(module_dir,\"tmp\",\"test/dogs\"))\n",
    "except OSError as e:\n",
    "    print(f'Error failed to make directory {e}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#In[4]\n",
    "\n",
    "#Define data path\n",
    "# Hacer lo mismo con todos los path\n",
    "CAT_DIR = '/kaggle/input/microsoft-catsvsdogs-dataset/PetImages/Cat'\n",
    "DOG_DIR = '/kaggle/input/microsoft-catsvsdogs-dataset/PetImages/Dog'\n",
    "\n",
    "TRAINING_DIR = \"/tmp/cats-v-dogs/training/\"\n",
    "VALIDATION_DIR = \"/tmp/cats-v-dogs/validation/\"\n",
    "\n",
    "TRAINING_CATS = os.path.join(TRAINING_DIR, \"cats/\")\n",
    "VALIDATION_CATS = os.path.join(VALIDATION_DIR, \"cats/\")\n",
    "\n",
    "TRAINING_DOGS = os.path.join(TRAINING_DIR, \"dogs/\")\n",
    "VALIDATION_DOGS = os.path.join(VALIDATION_DIR, \"dogs/\")\n",
    "\n",
    "# Define whether to include test split or not\n",
    "INCLUDE_TEST = True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#In[5]\n",
    "print(len(os.listdir('/tmp/cats-v-dogs/training/cats')))\n",
    "print(len(os.listdir('/tmp/cats-v-dogs/training/dogs')))\n",
    "\n",
    "print(len(os.listdir('/tmp/cats-v-dogs/validation/cats')))\n",
    "print(len(os.listdir('/tmp/cats-v-dogs/validation/dogs')))\n",
    "\n",
    "print(len(os.listdir('/tmp/cats-v-dogs/test/cats')))\n",
    "print(len(os.listdir('/tmp/cats-v-dogs/test/dogs')))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#In[6]\n",
    "\n",
    "def split_data(main_dir, training_dir, validation_dir, test_dir=None, include_test_split = True,  split_size=0.9):\n",
    "    \"\"\"\n",
    "    Splits the data into train validation and test sets (optional)\n",
    "\n",
    "    Args:\n",
    "    main_dir (string):  path containing the images\n",
    "    training_dir (string):  path to be used for training\n",
    "    validation_dir (string):  path to be used for validation\n",
    "    test_dir (string):  path to be used for test\n",
    "    include_test_split (boolen):  whether to include a test split or not\n",
    "    split_size (float): size of the dataset to be used for training\n",
    "    \"\"\"\n",
    "    files = []\n",
    "    for file in os.listdir(main_dir):\n",
    "        if  os.path.getsize(os.path.join(main_dir, file)): # check if the file's size isn't 0\n",
    "            files.append(file) # appends file name to a list\n",
    "    shuffled_files = random.sample(files,  len(files)) # shuffles the data\n",
    "    split = int(0.9 * len(shuffled_files)) #the training split casted into int for numeric rounding\n",
    "    train = shuffled_files[:split] #training split\n",
    "    split_valid_test = int(split + (len(shuffled_files)-split)/2)\n",
    "   \n",
    "    if include_test_split:\n",
    "        validation = shuffled_files[split:split_valid_test] # validation split\n",
    "        test = shuffled_files[split_valid_test:]\n",
    "    else:\n",
    "        validation = shuffled_files[split:]\n",
    "\n",
    "    for element in train:\n",
    "        copyfile(os.path.join(main_dir,  element), os.path.join(training_dir, element)) # copy files into training directory\n",
    "\n",
    "    for element in validation:\n",
    "        copyfile(os.path.join(main_dir,  element), os.path.join(validation_dir, element))# copy files into validation \n",
    "    if include_test_split:\n",
    "        for element in test:\n",
    "            copyfile(os.path.join(main_dir,  element), os.path.join(test_dir, element)) # copy files into test directory\n",
    "    print(\"Split sucessful!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#In[7]\n",
    "\n",
    "split_data(CAT_DIR, '/tmp/cats-v-dogs/training/cats', '/tmp/cats-v-dogs/validation/cats', '/tmp/cats-v-dogs/test/cats',INCLUDE_TEST, 0.9)\n",
    "split_data(DOG_DIR, '/tmp/cats-v-dogs/training/dogs', '/tmp/cats-v-dogs/validation/dogs','/tmp/cats-v-dogs/test/dogs',INCLUDE_TEST, 0.9)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#In[8]\n",
    "\n",
    "print(len(os.listdir('/tmp/cats-v-dogs/training/cats')))\n",
    "print(len(os.listdir('/tmp/cats-v-dogs/training/dogs')))\n",
    "\n",
    "print(len(os.listdir('/tmp/cats-v-dogs/validation/cats')))\n",
    "print(len(os.listdir('/tmp/cats-v-dogs/validation/dogs')))\n",
    "\n",
    "\n",
    "print(len(os.listdir('/tmp/cats-v-dogs/test/cats')))\n",
    "print(len(os.listdir('/tmp/cats-v-dogs/test/dogs')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#In [9]\n",
    "train_gen = ImageDataGenerator(\n",
    "        rescale=1./255)\n",
    "\n",
    "\n",
    "validation_gen =  ImageDataGenerator(\n",
    "        rescale=1./255.)\n",
    "\n",
    "if INCLUDE_TEST:\n",
    "    test_gen =  ImageDataGenerator(\n",
    "            rescale=1./255.)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#In[10]\n",
    "train_generator = train_gen.flow_from_directory(\n",
    "    '/tmp/cats-v-dogs/training',\n",
    "    target_size=(150, 150),\n",
    "    batch_size=64,\n",
    "    class_mode='binary')\n",
    "validation_generator = validation_gen.flow_from_directory(\n",
    "    '/tmp/cats-v-dogs/validation',\n",
    "    target_size=(150, 150),\n",
    "    batch_size=64,\n",
    "    class_mode='binary')\n",
    "\n",
    "if INCLUDE_TEST:\n",
    "    test_generator = test_gen.flow_from_directory(\n",
    "        '/tmp/cats-v-dogs/validation',\n",
    "        target_size=(150, 150),\n",
    "        batch_size=64,\n",
    "        class_mode='binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#In[11]\n",
    "    \n",
    "class_names = ['Cat', 'Dog']\n",
    "def plot_data(generator, n_images):\n",
    "    \"\"\"\n",
    "    Plots random data from dataset\n",
    "    Args:\n",
    "    generator: a generator instance\n",
    "    n_images : number of images to plot\n",
    "    \"\"\"\n",
    "    i = 1\n",
    "    images, labels = generator.next()\n",
    "    labels = labels.astype('int32')\n",
    "\n",
    "    plt.figure(figsize=(14, 15))\n",
    "    for image, label in zip(images, labels):\n",
    "        plt.subplot(4, 3, i)\n",
    "        plt.imshow(image)\n",
    "        plt.title(class_names[label])\n",
    "        plt.axis('off')\n",
    "        i += 1\n",
    "        if i == n_images:\n",
    "            break\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#In[12]\n",
    "plot_data(train_generator,7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#In[13]\n",
    "plot_data(validation_generator,7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#In[14]\n",
    "if INCLUDE_TEST:\n",
    "    plot_data(test_generator, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#In[15]\n",
    "inputs = tf.keras.layers.Input(shape=(150,150,3))\n",
    "x =  tf.keras.layers.Conv2D(32, (3,3), activation='relu')(inputs)\n",
    "x = tf.keras.layers.Conv2D(64, (3,3), activation='relu')(x)\n",
    "x = tf.keras.layers.MaxPooling2D(2,2)(x)\n",
    "\n",
    "x = tf.keras.layers.Conv2D(64, (3,3), activation='relu')(x)\n",
    "x = tf.keras.layers.Conv2D(128, (3,3), activation='relu')(x)\n",
    "x = tf.keras.layers.MaxPooling2D(2,2)(x)\n",
    "\n",
    "x = tf.keras.layers.Conv2D(128, (3,3), activation='relu')(x)\n",
    "x = tf.keras.layers.Conv2D(256, (3,3), activation='relu')(x)\n",
    "x = tf.keras.layers.GlobalAveragePooling2D()(x)\n",
    "x = Dense(1024,activation='relu')(x)\n",
    "x = tf.keras.layers.Dense(2, activation='softmax')(x) \n",
    "\n",
    "model = Model(inputs=inputs, outputs=x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#In[16]\n",
    "model.compile(optimizer=tf.keras.optimizers.RMSprop(learning_rate=0.001),\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#In[17]\n",
    "r = model.fit(\n",
    "        train_generator,\n",
    "        epochs=10,#Training longer could yield better results\n",
    "        validation_data=validation_generator)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#In[18]\n",
    "if INCLUDE_TEST:\n",
    "    model.evaluate(test_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#In[19]\n",
    "def plot_prediction(generator, n_images):\n",
    "    \"\"\"\n",
    "    Test the model on random predictions\n",
    "    Args:\n",
    "    generator: a generator instance\n",
    "    n_images : number of images to plot\n",
    "\n",
    "    \"\"\"\n",
    "    i = 1\n",
    "    # Get the images and the labels from the generator\n",
    "    images, labels = generator.next()\n",
    "    # Gets the model predictions\n",
    "    preds = model.predict(images)\n",
    "    predictions = np.argmax(preds, axis=1)\n",
    "    labels = labels.astype('int32')\n",
    "    plt.figure(figsize=(14, 15))\n",
    "    for image, label in zip(images, labels):\n",
    "        plt.subplot(4, 3, i)\n",
    "        plt.imshow(image)\n",
    "        if predictions[i] == labels[i]:\n",
    "            title_obj = plt.title(class_names[label])\n",
    "            plt.setp(title_obj, color='g') \n",
    "            plt.axis('off')\n",
    "        else:\n",
    "            title_obj = plt.title(class_names[label])\n",
    "            plt.setp(title_obj, color='r') \n",
    "            plt.axis('off')\n",
    "        i += 1\n",
    "        if i == n_images:\n",
    "            break\n",
    "    \n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#In[20]\n",
    "if INCLUDE_TEST:\n",
    "    plot_prediction(test_generator, 10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#In[21]\n",
    "plot_prediction(validation_generator, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#In[22]\n",
    "# Create a  model to visualize activation maps\n",
    "gp_weights =  model.get_layer('dense').get_weights()[0]\n",
    "activation_model = Model(model.inputs, outputs=(model.get_layer('conv2d_5').output, model.get_layer('dense_1').output))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#In[23]\n",
    "# Use the model to make predictions on the test generator\n",
    "images, _ = test_generator.next()\n",
    "features, results = activation_model.predict(images)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#In[24]\n",
    "def show_cam(image_index, features, results):\n",
    "    \"\"\"\n",
    "    Shows activation maps\n",
    "    Args:\n",
    "    image_index: index of image\n",
    "    features: the extracted features\n",
    "    results: model's predictions\n",
    "    \"\"\"\n",
    "    # takes the features of the chosen image\n",
    "    features_for_img = features[image_index,:,:,:]\n",
    "\n",
    "    # get the class with the highest output probability\n",
    "    prediction = np.argmax(results[image_index])\n",
    "\n",
    "    # get the gap weights at the predicted class\n",
    "    class_activation_weights = gp_weights[:,prediction]\n",
    "\n",
    "    # upsample the features to the image's original size (150 x 150)\n",
    "    class_activation_features = sp.ndimage.zoom(features_for_img, (150/30, 150/30, 1), order=2)\n",
    "\n",
    "    # compute the intensity of each feature in the CAM\n",
    "    cam_output  = np.dot(class_activation_features,class_activation_weights)\n",
    "\n",
    "    print('Predicted Class = ' +str(class_names[prediction])+ ', Probability = ' + str(results[image_index][prediction]))\n",
    "\n",
    "    # show the upsampled image\n",
    "    \n",
    "    plt.imshow(images[image_index])\n",
    "\n",
    "    # strongly classified (95% probability) images will be in green, else red\n",
    "    if results[image_index][prediction]>0.95:\n",
    "        cmap_str = 'Greens'\n",
    "    else:\n",
    "        cmap_str = 'Blues'\n",
    "\n",
    "    # overlay the cam output\n",
    "    plt.imshow(cam_output, cmap=cmap_str, alpha=0.5)\n",
    "\n",
    "    # display the image\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#In[25]\n",
    "def show_maps(desired_class, num_maps):\n",
    "    '''\n",
    "    goes through the first 10,000 test images and generates Cam activation maps\n",
    "    Args:\n",
    "    desired_class: class to show the maps for\n",
    "    num_maps: number of maps to be generated \n",
    "    '''\n",
    "    counter = 0\n",
    "    # go through the first 10000 images\n",
    "    for i in range(0,10000):\n",
    "        # break if we already displayed the specified number of maps\n",
    "        if counter == num_maps:\n",
    "            break\n",
    "\n",
    "        # images that match the class will be shown\n",
    "        if np.argmax(results[i]) == desired_class:\n",
    "            counter += 1\n",
    "            show_cam(i,features, results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#In[26]\n",
    "show_maps(desired_class=1, num_maps=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#In[27]\n",
    "show_maps(desired_class=0, num_maps=5\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Visualize training process\n",
    "#In[28]\n",
    "results = pd.DataFrame(r.history)\n",
    "results.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#In[29]\n",
    "fig = px.line(results,y=[results['accuracy'],results['val_accuracy']],template=\"seaborn\",color_discrete_sequence=['#fad25a','red'])\n",
    "fig.update_layout(   \n",
    "    title_font_color=\"#fad25a\", \n",
    "    xaxis=dict(color=\"#fad25a\",title='Epochs'), \n",
    "    yaxis=dict(color=\"#fad25a\")\n",
    " )\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#In[30]\n",
    "fig = px.line(results,y=[results['loss'],results['val_loss']],template=\"seaborn\",color_discrete_sequence=['#fad25a','red'])\n",
    "fig.update_layout(   \n",
    "    title_font_color=\"#fad25a\", \n",
    "    xaxis=dict(color=\"#fad25a\",title='Epochs'), \n",
    "    yaxis=dict(color=\"#fad25a\")\n",
    " )\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#In[31]\n",
    "train_gen_aug = ImageDataGenerator(\n",
    "        rescale=1./255,fill_mode='nearest',horizontal_flip=True,\n",
    "        rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    ")\n",
    "\n",
    "\n",
    "validation_gen_aug =  ImageDataGenerator(\n",
    "        rescale=1./255.)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#In[32]\n",
    "train_generator = train_gen_aug.flow_from_directory(\n",
    "        '/tmp/cats-v-dogs/training',\n",
    "        target_size=(150, 150),\n",
    "        batch_size=32,\n",
    "        class_mode='binary')\n",
    "validation_generator = validation_gen_aug.flow_from_directory(\n",
    "        '/tmp/cats-v-dogs/validation',\n",
    "        target_size=(150, 150),\n",
    "        batch_size=32,\n",
    "        class_mode='binary')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#In[33]\n",
    "\n",
    "inputs = tf.keras.layers.Input(shape=(150,150,3))\n",
    "x =  tf.keras.layers.Conv2D(32, (3,3), activation='relu')(inputs)\n",
    "x = tf.keras.layers.Conv2D(64, (3,3), activation='relu')(x)\n",
    "x = tf.keras.layers.MaxPooling2D(2,2)(x)\n",
    "\n",
    "x = tf.keras.layers.Conv2D(64, (3,3), activation='relu')(x)\n",
    "x = tf.keras.layers.Conv2D(128, (3,3), activation='relu')(x)\n",
    "x = tf.keras.layers.MaxPooling2D(2,2)(x)\n",
    "\n",
    "x = tf.keras.layers.Conv2D(128, (3,3), activation='relu')(x)\n",
    "x = tf.keras.layers.Conv2D(256, (3,3), activation='relu')(x)\n",
    "x = tf.keras.layers.MaxPooling2D(2,2)(x)\n",
    "\n",
    "\n",
    "x = tf.keras.layers.Flatten()(x)\n",
    "x = tf.keras.layers.Dense(1024, activation='relu')(x) \n",
    "x = tf.keras.layers.Dense(2, activation='softmax')(x) \n",
    "\n",
    "model_aug = Model(inputs=inputs, outputs=x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#In[34]\n",
    "model_aug.compile(optimizer=tf.keras.optimizers.RMSprop(learning_rate=0.001),\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics = ['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#In[35]\n",
    "r = model_aug.fit(\n",
    "        train_generator,\n",
    "        epochs=10,#Training longer could yield better results\n",
    "        validation_data=validation_generator)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#In[36]\n",
    "results = pd.DataFrame(r.history)\n",
    "results.tail()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#In[37]\n",
    "fig = px.line(results,y=[results['accuracy'],results['val_accuracy']],template=\"seaborn\",color_discrete_sequence=['#fad25a','red'])\n",
    "fig.update_layout(   \n",
    "    title_font_color=\"#fad25a\", \n",
    "    xaxis=dict(color=\"#fad25a\",title='Epochs'), \n",
    "    yaxis=dict(color=\"#fad25a\")\n",
    " )\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#In[38]\n",
    "fig = px.line(results,y=[results['loss'],results['val_loss']],template=\"seaborn\",color_discrete_sequence=['#fad25a','red'])\n",
    "fig.update_layout(   \n",
    "    title_font_color=\"#fad25a\", \n",
    "    xaxis=dict(color=\"#fad25a\",title='Epochs'), \n",
    "    yaxis=dict(color=\"#fad25a\")\n",
    " )\n",
    "fig.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
